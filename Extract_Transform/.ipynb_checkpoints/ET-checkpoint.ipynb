{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies and setup\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "# import psycopg2   # All SQL Loads should be done in a new .ipynb file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract CSV into pandas df\n",
    "df_ca = pd.read_csv('../resources/california-history.csv')\n",
    "df_ca.head()\n",
    "df_ca =len(df_ca)\n",
    "print(df_ca)\n",
    "# df_ca.dtypes  -- used to check data type. Uncomment to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate List of Data Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create json url query and variable for data request\n",
    "base_url = 'https://api.covidtracking.com/v1/states/ny/daily.json'\n",
    "data_dict = requests.get(base_url).json()\n",
    "\n",
    "print(json.dumps(data_dict, indent=4, sort_keys=True))\n",
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Set up dictionary of variables where data from api calls will be stored\n",
    "ny_data = {'date':[], 'state':[], 'deaths':[], \n",
    "           'Icu hospitalized':[], 'positive cases viral':[], 'positive increase':[], \n",
    "           'test results total':[], 'test increase':[]\n",
    "          }\n",
    "\n",
    "print('Retrieving NY Covid data')\n",
    "print('-' * 30)\n",
    "\n",
    "# forLoop to collect data and append to data_dict\n",
    "for data in data_dict:\n",
    "#     try:  -- not working; keep to use in future\n",
    "        ny_data['date'].append(data['date'])\n",
    "        ny_data['state'].append(data['state'])\n",
    "        ny_data['deaths'].append(data['deathIncrease'])\n",
    "#         ny_data['daily_hospitalization'].append(data['hospitalizedIncrease'])\n",
    "        ny_data['Icu hospitalized'].append(data['inIcuCurrently'])\n",
    "        ny_data['positive cases viral'].append(data['positiveCasesViral'])\n",
    "        ny_data['positive increase'].append(data['positiveIncrease'])\n",
    "        ny_data['test results total'].append(data['totalTestResults'])\n",
    "        ny_data['test increase'].append(data['totalTestResultsIncrease'])\n",
    "\n",
    "        # Use timer to delay request to not exceed query limits.\n",
    "        time.sleep(.075)\n",
    "#     except:   -- not working; keep to use in future\n",
    "#         print(f'Incomplete record for {data}. Skipping {data}.')\n",
    "\n",
    "#         print(ny_data)  -- used to validate append to ny_data dictionary; uncomment to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert panda dictionary to dataframe and export to csv\n",
    "ny_df = pd.DataFrame.from_dict(ny_data)\n",
    "\n",
    "ny_df['date'] = pd.to_datetime(ny_df['date'], format='%Y%m%d')\n",
    "ny_df.to_csv('../resources/ny_data.csv')\n",
    "ny_df.head()\n",
    "# ny_df.dtypes  -- used to check data type. Uncomment to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Cleaned CA Data\n",
    "\n",
    "clean_ca_df = pd.read_csv('../resources/clean_ca_data.csv', index_col=0)\n",
    "\n",
    "clean_ca_df.head()\n",
    "# clean_ca_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge CA and NY Data on Date\n",
    "clean_ca_df['date'] = pd.to_datetime(clean_ca_df['date'], errors=\"coerce\")\n",
    "# CA_NY_Data = pd.merge(ny_df, clean_ca_df, how=\"inner\", on=\"date\")\n",
    "CA_NY_Data = pd.concat([ny_df, clean_ca_df]).sort_index(kind=\"merge\")\n",
    "CA_NY_Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_NY_Data = CA_NY_Data.rename(columns= {\"date\":\"Date\",\n",
    "                                        \"state\":\"State\",\n",
    "                                        \"deaths\":\"Deaths\",\n",
    "                                        \"Icu hospitalized\":\"ICU Hospitalizations\",\n",
    "                                        \"positive cases viral\": \"Positive Viral Cases\",\n",
    "                                        \"positive increase\": \"Positive Increase\",\n",
    "                                        \"test results total\": \"Total Test Results\",\n",
    "                                        \"test increase\": \"Test Increase\",\n",
    "                                        })\n",
    "# CA_NY_Data = CA_NY_Data.dropna()\n",
    "# CA_NY_Data = CA_NY_Data.reset_index(drop = True)\n",
    "CA_NY_Data.fillna(0, inplace=True)\n",
    "\n",
    "CA_NY_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scrape iframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve COVID graphs from Syracuse website iframes\n",
    "# Set url query path\n",
    "path='https://www.syracuse.com/coronavirus-ny/'\n",
    "f = urlopen(path)\n",
    "html = str(f.read())\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "txt = soup.find_all('iframe')\n",
    "\n",
    "for element in txt:\n",
    "    print(element.attrs[\"src\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retrieve data from interactive chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied-pasted https://datawrapper.dwcdn.net/ijEiy/2/, a dynamic webpage \n",
    "# into browser and inspected page. Examined Network, then XHR to get the link for CSV data.\n",
    "url = 'https://static.dwcdn.net/data/ijEiy.csv?v=1623222240000'\n",
    "proxies = {}\n",
    "response = requests.get(url=url, proxies=proxies)\n",
    "with open(\"../resources/covid_chart_data.csv\", \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
